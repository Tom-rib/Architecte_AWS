# S3 Integration avec AWS Glue ðŸ“¦

Lire et Ã©crire dans S3 depuis Glue.

---

## Lire depuis S3

### Depuis Catalog (RecommandÃ©)

```python
# Simple - crawler a dÃ©tectÃ© le schÃ©ma
df = glueContext.create_dynamic_frame.from_catalog(
    database="default",
    table_name="customers"
)
```

### Depuis Path Directement

```python
# Pas besoin de crawler
df = glueContext.create_dynamic_frame.from_options(
    format_options={"multiline": False},
    connection_type="s3",
    format="csv",
    connection_options={"path": "s3://mybucket/customers/"},
    transformation_ctx="datasource"
)
```

---

## Ã‰crire vers S3

### Simple

```python
glueContext.write_dynamic_frame.from_options(
    frame=df,
    connection_type="s3",
    connection_options={"path": "s3://output/clean/"},
    format="parquet"
)
```

### Avec Partitions

```python
glueContext.write_dynamic_frame.from_options(
    frame=df,
    connection_type="s3",
    connection_options={
        "path": "s3://output/customers/",
        "partitionKeys": ["year", "month"]  # Partition by year/month
    },
    format="parquet"
)
```

---

## Formats

```
CSV:
â”œâ”€ Lisible
â”œâ”€ Volumineux
â””â”€ Lent pour requÃªtes

JSON:
â”œâ”€ StructurÃ©
â”œâ”€ CompressÃ©
â””â”€ Bon pour API

Parquet:
â”œâ”€ CompressÃ©
â”œâ”€ Rapide requÃªtes
â””â”€ Excellent pour Glue/Athena
```

---

## Best Practices

```
âœ… Partitionner par time
â”œâ”€ year=2024/month=01/
â”œâ”€ year=2024/month=02/
â””â”€ Queries scannent seulement needed partitions

âœ… Utiliser Parquet
â”œâ”€ Compression native
â”œâ”€ Schema preserved
â””â”€ Compatible Athena, Redshift Spectrum

âœ… Nettoyer path
â”œâ”€ Pas de fichiers temporaires
â”œâ”€ Pas de _logs ou .tmp
â””â”€ Structures claires
```

---

**CoÃ»t**: S3 storage + requÃªtes Glue
