# CloudWatch Alarms - Guide Complet & RÃ©fÃ©rence ğŸš¨

Tout sur la crÃ©ation d'alarmes CloudWatch et actions associÃ©es.

---

## TABLE DES MATIÃˆRES

1. [Concepts Fondamentaux](#concepts-fondamentaux)
2. [Metric Alarms](#metric-alarms)
3. [Composite Alarms](#composite-alarms)
4. [Anomaly Detection](#anomaly-detection)
5. [Actions d'Alarme](#actions-dalarme)
6. [Best Practices](#best-practices)

---

## Concepts Fondamentaux

### Ã‰tats d'une Alarme

```
                    OK
                   â†‘ â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“                      â†“
      ALARM            INSUFFICIENT_DATA
   (Condition TRUE)    (Pas assez donnÃ©es)

OK (Vert) âœ…
â”œâ”€ Condition FALSE
â”œâ”€ MÃ©trique < seuil
â”œâ”€ Tout normal
â””â”€ Email: "OK" optionnelle

ALARM (Rouge) ğŸš¨
â”œâ”€ Condition TRUE
â”œâ”€ MÃ©trique >= seuil
â”œâ”€ Action dÃ©clenchÃ©e
â””â”€ Email: Alert

INSUFFICIENT_DATA (Gris) â“
â”œâ”€ Juste crÃ©Ã©e
â”œâ”€ Historique insuffisant
â”œâ”€ Attend 5 minutes
â””â”€ Pas d'action
```

### PÃ©riode d'Ã‰valuation

```
Alarme: CPU > 80%
â”‚
â”œâ”€ Period: 5 minutes
â”œâ”€ EvaluationPeriods: 2
â”‚
â””â”€ TRIGGER si:
   CPU > 80% pour 2 pÃ©riodes
   = 10 minutes d'affilÃ©e
   (Ã©vite faux positifs)
```

**Pourquoi 2 pÃ©riodes ?**
- Spike CPU 85% 1 seconde : ignorÃ©
- CPU 85% pendant 10 min : ALARME (grave)

---

## Metric Alarms

### Structure

```
Metric Alarm
â”‚
â”œâ”€ MÃ©trique: CPUUtilization
â”œâ”€ Comparaison: GreaterThanOrEqualToThreshold
â”œâ”€ Seuil: 80
â”œâ”€ Statistique: Average
â”œâ”€ PÃ©riode: 5 minutes
â”œâ”€ Ã‰valuations: 2 pÃ©riodes
â”‚
â”œâ”€ IF CPUUtilization >= 80 FOR 10 min
â”‚  THEN ALARM
â”‚
â””â”€ Actions:
   â”œâ”€ Envoyer SNS
   â”œâ”€ Auto Scaling (augmenter)
   â”œâ”€ EC2 Action (reboot)
   â””â”€ OpsCenter (ticket)
```

### CrÃ©er une Metric Alarm

**Console AWS**

```
1. CloudWatch > Alarms > Create Alarm
2. Select Metric
   â”œâ”€ Service: EC2
   â”œâ”€ Metric Name: CPUUtilization
   â””â”€ Instance: i-1234567890

3. Alarm Details
   â”œâ”€ Alarm Name: ec2-cpu-high
   â”œâ”€ Description: CPU > 80%
   â””â”€ Alarm Condition:
      â””â”€ Threshold: 80 %

4. Alarm State Trigger
   â”œâ”€ Statistic: Average
   â”œâ”€ Period: 5 minutes
   â”œâ”€ Evaluation: 1 datapoint
   â”œâ”€ Comparison: >=
   â””â”€ Threshold: 80

5. Actions
   â”œâ”€ Alarm State: ALARM
   â”œâ”€ Send notification to: SNS topic
   â””â”€ Select topic: alerts-production

6. Create
```

**CLI**

```bash
aws cloudwatch put-metric-alarm \
  --alarm-name ec2-cpu-high \
  --alarm-description "CPU > 80%" \
  --metric-name CPUUtilization \
  --namespace AWS/EC2 \
  --statistic Average \
  --period 300 \
  --threshold 80 \
  --comparison-operator GreaterThanOrEqualToThreshold \
  --evaluation-periods 1 \
  --alarm-actions arn:aws:sns:eu-west-3:123456789:alerts-production \
  --region eu-west-3
```

**Python (Boto3)**

```python
import boto3

cloudwatch = boto3.client('cloudwatch')

cloudwatch.put_metric_alarm(
    AlarmName='ec2-cpu-high',
    ComparisonOperator='GreaterThanOrEqualToThreshold',
    EvaluationPeriods=1,
    MetricName='CPUUtilization',
    Namespace='AWS/EC2',
    Period=300,
    Statistic='Average',
    Threshold=80.0,
    ActionsEnabled=True,
    AlarmActions=[
        'arn:aws:sns:eu-west-3:123456789:alerts-production'
    ],
    AlarmDescription='EC2 CPU > 80%',
)
```

### Statistiques Disponibles

```
Average
â”œâ”€ Moyenne de la mÃ©trique
â”œâ”€ Exemple: CPU moyen 45%
â””â”€ RecommandÃ© pour la plupart

Maximum
â”œâ”€ Pic maximum
â”œâ”€ Exemple: CPU peak 95%
â””â”€ Bon pour dÃ©tecter spikes

Minimum
â”œâ”€ Valeur minimale
â”œâ”€ Exemple: CPU min 5%
â””â”€ Moins utilisÃ©

Sum
â”œâ”€ Total cumulatif
â”œâ”€ Exemple: Erreurs total 150
â””â”€ Bon pour comptes

SampleCount
â”œâ”€ Nombre de points
â”œâ”€ Exemple: 120 invocations
â””â”€ Bon pour traffic

pNN.NN (Percentile)
â”œâ”€ Exemple: p99 = 99Ã¨me percentile
â”œâ”€ p99 Latency = 2.5 secondes
â””â”€ Bon pour SLA
```

### Comparateurs

```
GreaterThanOrEqualToThreshold (>=)
â”œâ”€ x >= 80
â””â”€ IdÃ©al pour "trop haut"

GreaterThanThreshold (>)
â”œâ”€ x > 80
â””â”€ Strictement supÃ©rieur

LessThanOrEqualToThreshold (<=)
â”œâ”€ x <= 5
â””â”€ IdÃ©al pour "trop bas"

LessThanThreshold (<)
â”œâ”€ x < 5
â””â”€ Strictement infÃ©rieur

LessThanLowerOrGreaterThanUpperThreshold
â”œâ”€ x < 10 OR x > 80
â””â”€ Plage anormale
```

---

## Composite Alarms

### Qu'est-ce ?

Alarme basÃ©e sur **plusieurs autres alarms**, avec **logique AND/OR**

```
Composite Alarm: "Production Down"
â”‚
â””â”€ IF (CPU High) AND (Latency High) AND (Errors High)
   THEN Send Alert

Au lieu de 3 alertes sÃ©parÃ©es
```

### CrÃ©er Composite Alarm

**Console**

```
1. CloudWatch > Alarms > Create Alarm
2. Select: Composite Alarm
3. Name: production-critical
4. Alarm Rule:
   â”œâ”€ (ALARM ec2-cpu-high) AND
   â”œâ”€ (ALARM api-latency-high) AND
   â””â”€ (ALARM lambda-errors-high)
5. Actions: Send SNS
6. Create
```

**CLI**

```bash
aws cloudwatch put-composite-alarm \
  --alarm-name production-critical \
  --alarm-rule "ALARM(ec2-cpu-high) AND ALARM(api-latency-high)" \
  --alarm-actions arn:aws:sns:eu-west-3:123456789:alerts-production
```

### Logique Possible

```
Conditions Simples
â”œâ”€ ALARM(alarm-name) - Vrai si ALARM
â”œâ”€ OK(alarm-name) - Vrai si OK
â””â”€ INSUFFICIENT_DATA(alarm-name)

OpÃ©rateurs
â”œâ”€ AND - Toutes vraies
â”œâ”€ OR - Au moins une vraie
â””â”€ NOT - OpposÃ©

Exemples
â”œâ”€ ALARM(cpu-high) AND ALARM(mem-high)
   â†’ Alarme si CPU ET RAM hauts

â”œâ”€ ALARM(api-error) OR ALARM(db-error)
   â†’ Alarme si API OU DB en erreur

â”œâ”€ NOT INSUFFICIENT_DATA(cpu)
   â†’ Alarme si donnÃ©es disponibles
```

---

## Anomaly Detection

### Qu'est-ce ?

Alarme qui dÃ©tecte automatiquement **patterns anormaux** via ML

```
Anomaly Detection
â”‚
â”œâ”€ ML apprend pattern normal
â”‚  (2 semaines historique)
â”‚
â”œâ”€ DÃ©tecte dÃ©viation > 2 sigma
â”‚  (probabilitÃ© < 5%)
â”‚
â””â”€ Trigger si anormal
   Exemple: CPU normalement 30%
           Soudain 70% â†’ ANOMALY
```

### CrÃ©er Anomaly Alarm

**Console**

```
1. CloudWatch > Alarms > Create Alarm
2. Select Metric
3. Anomaly Detector
   â”œâ”€ Select Metric: CPUUtilization
   â””â”€ Anomaly Detector automatically created
4. Threshold: 2 (sigma)
5. Actions: SNS
6. Create
```

**CLI**

```bash
aws cloudwatch put-metric-alarm \
  --alarm-name cpu-anomaly \
  --comparison-operator LessThanLowerOrGreaterThanUpperThreshold \
  --evaluation-periods 1 \
  --metrics '[{
    "Id": "m1",
    "ReturnData": true,
    "MetricStat": {
      "Metric": {"Namespace": "AWS/EC2", "MetricName": "CPUUtilization"},
      "Period": 300,
      "Stat": "Average"
    }
  }, {
    "Id": "ad1",
    "Expression": "ANOMALY_DETECTION_BAND(m1, 2)",
    "ReturnData": true
  }]' \
  --threshold-metric-id ad1
```

### Sigma (Ïƒ)

```
2 sigma = 95% confiance
â”œâ”€ Catches 5% anormal
â”œâ”€ Moins sensible
â””â”€ RecommandÃ©

3 sigma = 99.7% confiance
â”œâ”€ Catches 0.3% anormal
â”œâ”€ Plus sensible
â””â”€ Pour trÃ¨s critique
```

---

## Actions d'Alarme

### SNS Notification

```
Alarm Ã‰tat Change
â”‚
â””â”€ Envoyer message SNS
   â”‚
   â”œâ”€ Topic: alerts-production
   â”‚
   â”œâ”€ Message contient:
   â”‚  â”œâ”€ Alarm Name
   â”‚  â”œâ”€ Reason
   â”‚  â”œâ”€ Metric Value
   â”‚  â””â”€ Timestamp
   â”‚
   â””â”€ Subscribers reÃ§oivent:
      â”œâ”€ Email
      â”œâ”€ SMS
      â”œâ”€ Lambda
      â””â”€ HTTP
```

### Auto Scaling Action

```
Alarm ALARM State
â”‚
â””â”€ Trigger Auto Scaling Policy
   â”‚
   â”œâ”€ Scale UP: Ajouter 2 instances
   â”‚
   â””â”€ Scale DOWN: Supprimer 1 instance
```

### EC2 Instance Action

```
Alarm ALARM State
â”‚
â””â”€ EC2 Action
   â”‚
   â”œâ”€ Stop Instance
   â”œâ”€ Terminate Instance
   â”œâ”€ Reboot Instance
   â””â”€ Recover Instance
```

### Lambda Action

```
Alarm ALARM State
â”‚
â””â”€ Invoke Lambda Function
   â”‚
   â”œâ”€ Passer Alarm Details en input
   â”‚
   â””â”€ Lambda peut:
      â”œâ”€ Envoyer Slack message
      â”œâ”€ CrÃ©er ticket Jira
      â”œâ”€ Lancer remediation
      â””â”€ Notifier Ã©quipe
```

### OpsCenter (Incident Management)

```
Alarm ALARM State
â”‚
â””â”€ Create OpsCenter Item
   â”‚
   â”œâ”€ Ticket automatique
   â”œâ”€ Historique
   â””â”€ Track resolution
```

### CloudFormation Action

```
Alarm ALARM State
â”‚
â””â”€ Update CloudFormation Stack
   â”‚
   â””â”€ Change infrastructure
      Exemple: Auto-heal resource
```

---

## Configuration Multi-Service

### Alarmes RecommandÃ©es Par Service

**EC2**

```
1. CPU High (>80%)
2. Network In/Out Unusual
3. Instance Status Check Failed
```

**Lambda**

```
1. Errors > 1%
2. Throttles > 0
3. Duration > 5 sec
```

**RDS**

```
1. Connections > 80%
2. CPU > 80%
3. Failed SQL Statements > 5
```

**API Gateway**

```
1. 4XX Errors > 5%
2. 5XX Errors > 1%
3. Latency > 1000 ms
```

**DynamoDB**

```
1. Read Throttles > 0
2. Write Throttles > 0
3. Replication Latency > 1 sec
```

### Centraliser sur 1 Topic SNS

```
Topic: alerts-production
â”‚
â”œâ”€ EC2 Alarm 1 â†’ publishes
â”œâ”€ EC2 Alarm 2 â†’ publishes
â”œâ”€ Lambda Alarm 1 â†’ publishes
â”œâ”€ RDS Alarm 1 â†’ publishes
â””â”€ API Alarm 1 â†’ publishes

1 Topic = Facile gÃ©rer
1 Email = ReÃ§oit toutes
```

---

## Best Practices

### 1. Seuils RÃ©alistes

```
âŒ MAUVAIS
CPU > 90%
â”œâ”€ Trop stricte
â”œâ”€ Trop alertes
â””â”€ "Alarm fatigue"

âœ… BON
CPU > 80%
â”œâ”€ BasÃ© historique
â”œâ”€ Temps rÃ©agir
â””â”€ Ã‰vite faux positif
```

### 2. Statistic AppropriÃ©e

```
âŒ MAUVAIS
CPU Maximum > 80%
â”œâ”€ Spike 1 sec = alarme
â”œâ”€ Faux positifs

âœ… BON
CPU Average > 80% for 2 periods
â”œâ”€ 10 min d'affilÃ©e
â”œâ”€ ProblÃ¨me rÃ©el
```

### 3. Ã‰valuation PÃ©riodes

```
âŒ MAUVAIS
PÃ©riode 1 min, Evaluations 1
â”œâ”€ TrÃ¨s sensible
â”œâ”€ Spike mineur = alarme

âœ… BON
PÃ©riode 5 min, Evaluations 2
â”œâ”€ 10 min d'affilÃ©e
â”œâ”€ Moins sensible
â”œâ”€ CoÃ»ts rÃ©duits
```

### 4. Actions CohÃ©rentes

```
âŒ MAUVAIS
Alarm CPU High
â”œâ”€ Action: SNS
â”œâ”€ Alarm Memory High
   â””â”€ Action: Rien
â”œâ”€ Alarm Errors High
   â””â”€ Action: Lambda (auto-restart)

âœ… BON
Toutes alertes â†’ SNS topic unique
Logique similaire
```

### 5. Monitoring des Alarms

```
âŒ MAUVAIS
CrÃ©er alarms et ignorer

âœ… BON
Monitorer alarms elles-mÃªmes:
â”œâ”€ Sont-elles dÃ©clenchÃ©es ?
â”œâ”€ SNS fonctionne ?
â”œâ”€ Action exÃ©cutÃ©e ?
â””â”€ Seuils toujours pertinents ?
```

---

## Troubleshooting Alarms

### Alarm ne se dÃ©clenche pas

```
Causes possibles:
â”œâ”€ INSUFFICIENT_DATA (pas assez historique)
â”‚  â†’ Attendre 5 minutes
â”‚
â”œâ”€ MÃ©trique n'existe pas
â”‚  â†’ VÃ©rifier nom mÃ©trique
â”‚
â”œâ”€ Seuil trop haut
â”‚  â†’ Baisser threshold
â”‚
â””â”€ SNS ne fonctionne pas
   â†’ VÃ©rifier Topic, Subscribers
```

### Trop d'alertes (Alarm Fatigue)

```
Solutions:
â”œâ”€ Augmenter seuil
â”œâ”€ Augmenter Ã©valuations (2-3)
â”œâ”€ Utiliser Composite Alarms
â”œâ”€ Filtrer SNS
â””â”€ Grouper dans Dashboard
```

### Alert n'arrive pas

```
Causes:
â”œâ”€ Subscriber non-confirmÃ© (email)
â”‚  â†’ Confirmer lien email
â”‚
â”œâ”€ SNS Topic vide
â”‚  â†’ Ajouter subscribers
â”‚
â”œâ”€ Permissions IAM
â”‚  â†’ VÃ©rifier policy
â”‚
â””â”€ Limite dÃ©passÃ©e
   â†’ VÃ©rifier coÃ»ts/quotas
```

---

## Free Tier CloudWatch Alarms

```
Gratuit:
â”œâ”€ 10 alarms/mois
â”œâ”€ Metric Alarms
â”œâ”€ SNS notifications
â””â”€ Standard Monitoring

Payant:
â”œâ”€ +0.10â‚¬ / alarm / mois
â”œâ”€ Detailed Monitoring (1 min)
â”œâ”€ Composite Alarms (+0.50â‚¬)
â””â”€ Custom Metrics (0.30â‚¬ / metric)

StratÃ©gie Free Tier (10 alarms):
â”œâ”€ 1 EC2 CPU High
â”œâ”€ 1 Lambda Errors
â”œâ”€ 1 RDS Connections
â”œâ”€ 1 API 5XX Errors
â”œâ”€ 1 API Latency
â”œâ”€ 1 DynamoDB Read Throttles
â”œâ”€ 1 DynamoDB Write Throttles
â”œâ”€ 1 S3 Errors (optionnel)
â”œâ”€ 1 Composite Alarm (multi-service)
â””â”€ 1 Reserve (futur)
```

---

**SUITE** : Voir GUIDE-SETUP-JOB5.md pour mettre en place les 10 alarmes du projet
